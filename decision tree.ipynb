{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  How a decision tree works\n",
    "\n",
    "### This notebook shows basic binary outcome decision tree algorithm from scratch. It also creates a decision tree regressor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A decision tree predicts data by asking a series of binary questions. Is the data in this column greater than or less than this value? If less proceed to the left node, if greater proceed to the right. Once an end condition is met, which for this example will be that all leafs have at least 5 observations, that branch is terminated and the prediction at that leaf is then determined by the majority class or average value of all data in the leaf."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Determining the split point"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to determine split points by finding the column in the data and the point in that column where splitting the data gives us the most information. How do we define information gain? \n",
    "\n",
    "Well we want the leafs in our tree to be as homogenous as possible. Consider a data set with 50 % cClass 1 and 50% Class 2. Blindly picking an observation in this row yields a totally random result. By comparison, if the result were all or mostly Class 1, there would be no or little randomness to the outcome.\n",
    "\n",
    "This can be represented by the entropy function. If we define p1 as the percentage of observations with class 1, and p2 as the percentage of observations with class 2:\n",
    "\n",
    "\\begin{align}\n",
    "Entropy  = -p1*log(p1) - p2*log(p2)\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    " def get_entropy(y):\n",
    "        '''\n",
    "        Computes the entropy of y.\n",
    "        '''\n",
    "        p1 = np.mean(y)\n",
    "        p2 = 1 - p1\n",
    "        \n",
    "        if p1 == 0 or p2 == 0:\n",
    "            return 0\n",
    "        else:\n",
    "            return -np.log(p1)*p1 - np.log(p2)*p2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we split the data at a point, and get the entropy of the new data on both sides of the split, and take the average of those values weighted by the number of observations in each, we can access the combined entropy after the split. The information gain is then the entropy before the split - the entropy after the split. How can we find this point? Well, we can just loop through all columns in the data, split between every point, and through trial and error determine which point works best. Slow, but effective!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def maximum_info_gain(x_j, y, min_obs):\n",
    "        '''\n",
    "        Here x_j represents a single column from training data and y represents the outcomes. Stop splitting\n",
    "        if a split would have less than min_obs in the leaf.\n",
    "        '''\n",
    "        #sort the data\n",
    "        data = zip(x_j,y)\n",
    "        data = sorted(data, key = lambda x: x[0])\n",
    "        sorted_x_j, sorted_y = zip(*data)\n",
    "        sorted_x_j, sorted_y = np.array(sorted_x_j), np.array(sorted_y)\n",
    "        \n",
    "        # loop through the sorted data and split at every midpoint between points\n",
    "        info_gains = []\n",
    "        for i in range(len(x_j)-1):\n",
    "            split_point = (float(sorted_x_j[i]) + float(sorted_x_j[i+1]))/2\n",
    "            left_x, left_y = sorted_x_j[sorted_x_j < split_point], sorted_y[sorted_x_j < split_point]\n",
    "            right_x, right_y = sorted_x_j[sorted_x_j >= split_point], sorted_y[sorted_x_j >= split_point]\n",
    "            \n",
    "            #stop splitting if the split has less than minimum observation threshold.\n",
    "            if len(left_x) < min_obs or len(right_x) < min_obs:\n",
    "                continue\n",
    "            \n",
    "            #calculate new pooled entropy\n",
    "            left_entropy = get_entropy(left_y)\n",
    "            right_entropy = get_entropy(right_y)\n",
    "            total_entropy = left_entropy*len(left_x)/len(x_j) + right_entropy*len(right_x)/len(x_j)\n",
    "            \n",
    "            #append info gain\n",
    "            info_gains.append((split_point, get_entropy(y) - total_entropy))\n",
    "        \n",
    "        #return max gain\n",
    "        return(max(info_gains, key = lambda x:x[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_points, info_gains = zip(*[maximum_info_gain(X[:,x_j],self.y) for x_j in range(X.shape[1])])\n",
    "max_info_gain = max(info_gains)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the tree structure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to create the architecture to make a decision tree. We take all the training data, find the best split point, and then create child nodes on the left and the right of the split point. On each child node, we recursively do this until we hit the minimum allowable observations in a node. Then we vote on the result in each node. The decision tree fit function makes more sense in the context of a class, which will be depicted later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_vote(y_vals):\n",
    "    '''\n",
    "    Returns most common value in y_vals\n",
    "    '''\n",
    "    y_0 = len([y for y in y_vals if y == 0])\n",
    "\n",
    "    if y_0 >= (len(y_vals) - y_0):\n",
    "        return 0\n",
    "    else:\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All that is left is to traverse the tree. For each observation, we traverse the tree. When we finally hit a terminal leaf node, which will be defined by not having a split point, we return the majority vote in the class. I've wrapped all the above functions, plus a fit and predict function, into the class below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecisionTreeClassifier:\n",
    "\n",
    "    def __init__(self, min_obs=5):\n",
    "        self.min_obs = min_obs\n",
    "    \n",
    "    \n",
    "    def get_entropy(self, y):\n",
    "        '''\n",
    "        Computes the entropy of y.\n",
    "        '''\n",
    "        p1 = np.mean(y)\n",
    "        p2 = 1 - p1\n",
    "        \n",
    "        if p1 == 0 or p2 == 0:\n",
    "            return 0\n",
    "        else:\n",
    "            return -np.log(p1)*p1 - np.log(p2)*p2\n",
    "  \n",
    "    def maximum_info_gain(self,x_j, y):\n",
    "        '''\n",
    "        Here x_j represents a single column from training data and y represents the outcomes. Stop splitting\n",
    "        if a split would have less than min_obs in the leaf.\n",
    "        '''\n",
    "        #sort the data\n",
    "        data = zip(x_j,y)\n",
    "        data = sorted(data, key = lambda x: x[0])\n",
    "        sorted_x_j, sorted_y = zip(*data)\n",
    "        sorted_x_j, sorted_y = np.array(sorted_x_j), np.array(sorted_y)\n",
    "        \n",
    "        # loop through the sorted data and split at every midpoint between points\n",
    "        info_gains = []\n",
    "        for i in range(len(x_j)-1):\n",
    "            split_point = (float(sorted_x_j[i]) + float(sorted_x_j[i+1]))/2\n",
    "            left_x, left_y = sorted_x_j[sorted_x_j < split_point], sorted_y[sorted_x_j < split_point]\n",
    "            right_x, right_y = sorted_x_j[sorted_x_j >= split_point], sorted_y[sorted_x_j >= split_point]\n",
    "            \n",
    "            #stop splitting if the split has less than minimum observation threshold.\n",
    "            if len(left_x) < self.min_obs or len(right_x) < self.min_obs:\n",
    "                continue\n",
    "            \n",
    "            #calculate new pooled entropy\n",
    "            left_entropy = self.get_entropy(left_y)\n",
    "            right_entropy = self.get_entropy(right_y)\n",
    "            total_entropy = left_entropy*len(left_x)/len(x_j) + right_entropy*len(right_x)/len(x_j)\n",
    "            \n",
    "            #append info gain\n",
    "            info_gains.append((split_point, self.entropy - total_entropy))\n",
    "        \n",
    "        return(max(info_gains, key = lambda x:x[1]))\n",
    "        \n",
    "            \n",
    "    def do_vote(self, y_vals):\n",
    "        '''\n",
    "        Returns most common value in y_vals\n",
    "        '''\n",
    "        y_0 = len([y for y in y_vals if y == 0])\n",
    "        \n",
    "        if y_0 >= (len(y_vals) - y_0):\n",
    "            return 0\n",
    "        else:\n",
    "            return 1\n",
    "        \n",
    "    def fit(self,X,y):\n",
    "        '''\n",
    "        Fits a decision tree given training data X and outcomes y.\n",
    "        '''\n",
    "        #initializing some values\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.entropy = self.get_entropy(self.y)\n",
    "        self.vote = None\n",
    "        self.split_point = None\n",
    "        self.split_col = None\n",
    "        \n",
    "        #if X has enough observations and y isn't uniform we proceed\n",
    "        if self.X.shape[0] > self.min_obs and len(np.unique(self.y))>1:\n",
    "            \n",
    "            # get the best split point in each column\n",
    "            split_points, info_gains = zip(*[self.maximum_info_gain(self.X[:,x_j],self.y) for x_j in range(X.shape[1])])\n",
    "            print('prospective split points {}'.format(split_points))\n",
    "            print('prospective info_gains {}'.format(info_gains))\n",
    "            \n",
    "            max_info_gain = max(info_gains)\n",
    "            \n",
    "            \n",
    "            #if we can't gain info stop here and get the vote\n",
    "            if max_info_gain == 0:\n",
    "                self.vote = self.do_vote(self.y)\n",
    "                return None\n",
    "            \n",
    "            #choose best column\n",
    "            self.split_col = info_gains.index(max_info_gain)\n",
    "            self.split_point = split_points[self.split_col]\n",
    "            \n",
    "            #create new nodes for the children\n",
    "            self.left = DecisionTreeClassifier(min_obs = self.min_obs)\n",
    "            self.right = DecisionTreeClassifier(min_obs = self.min_obs)\n",
    "            \n",
    "            #generate splits\n",
    "            X_left, y_left = X[X[:,self.split_col] < self.split_point,:],  y[X[:,self.split_col] < self.split_point]\n",
    "            X_right, y_right = X[X[:,self.split_col] >= self.split_point,:],  y[X[:,self.split_col] >= self.split_point]\n",
    "            \n",
    "            #fit the children nodes\n",
    "            print('splitting at column {}, value {}'.format(self.split_col, self.split_point))\n",
    "            self.left.fit(X_left, y_left)\n",
    "            self.right.fit(X_right, y_right)\n",
    "        \n",
    "        #if X doesn't have enough observations, vote\n",
    "        else:\n",
    "            self.vote = self.do_vote(self.y)\n",
    "            \n",
    "    def predict_one(self, row):\n",
    "        '''\n",
    "        for one observation, traverses the tree and predicts the vote of the leaf it ends up in.\n",
    "        '''\n",
    "        \n",
    "        # if there's no split in this node, we return the vote. We always eventually end here.\n",
    "        if not self.split_point:\n",
    "            return self.vote\n",
    "        # otherwise if the value is greater than the split point, call predict on the right node\n",
    "        elif row[self.split_col] >= self.split_point:\n",
    "            return(self.right.predict_one(row))\n",
    "        # otherwise if the value is less than the split point, call predict on the left node\n",
    "        else:\n",
    "            return(self.left.predict_one(row))\n",
    "\n",
    "        \n",
    "    def predict(self, X):\n",
    "        '''\n",
    "        returns preditions for all X values\n",
    "        '''\n",
    "        preds = []\n",
    "        for row in X:\n",
    "            preds.append(self.predict_one(row))\n",
    "        \n",
    "        return(preds)\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing it out\n",
    "\n",
    "I'll create some simple test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "testClassifier = DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.concatenate([np.arange(1,21).reshape(20,1),np.array([0,1]*10).reshape(20,1) ],axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.array([0]*10 + [1,0]*5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x174ddb057b8>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x174dda56f98>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(X[:,0],X[:,1], c = y) # split on X1 < 10, and then if X2 = 0 predict class 1, otherwise, class 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prospective split points (10.5, 0.5)\n",
      "prospective info_gains (0.21576155433883565, 0.21576155433883565)\n",
      "splitting at column 0, value 10.5\n",
      "prospective split points (15.5, 0.5)\n",
      "prospective info_gains (0.020135513550688766, 0.6931471805599453)\n",
      "splitting at column 1, value 0.5\n"
     ]
    }
   ],
   "source": [
    "testClassifier.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = testClassifier.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds == y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression tree\n",
    "\n",
    "### We can also make a tree to handle problems with a continuous outcome - a regression tree."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It will work exactly the same way as above, except the entropy function will just be the standard deviation of the dependent variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecisionTreeRegressor:\n",
    "    \n",
    "    def __init__(self, min_obs=5):\n",
    "        self.min_obs = min_obs\n",
    "    \n",
    "    def get_entropy(self, y):\n",
    "        \n",
    "        return np.std(y)\n",
    "    \n",
    "    def maximum_info_gain(self,x_j, y):\n",
    "        \n",
    "        data = zip(x_j,y)\n",
    "        data = sorted(data, key = lambda x: x[0])\n",
    "        sorted_x_j, sorted_y = zip(*data)\n",
    "        sorted_x_j, sorted_y = np.array(sorted_x_j), np.array(sorted_y)\n",
    "        \n",
    "        info_gains = []\n",
    "        for i in range(len(x_j)-1):\n",
    "            split_point = (float(sorted_x_j[i]) + float(sorted_x_j[i+1]))/2\n",
    "            left_x, left_y = sorted_x_j[sorted_x_j < split_point], sorted_y[sorted_x_j < split_point]\n",
    "            right_x, right_y = sorted_x_j[sorted_x_j >= split_point], sorted_y[sorted_x_j >= split_point]\n",
    "            \n",
    "            if len(left_x) < self.min_obs or len(right_x) < self.min_obs:\n",
    "                continue\n",
    "            \n",
    "            left_entropy = self.get_entropy(left_y)\n",
    "            right_entropy = self.get_entropy(right_y)\n",
    "            total_entropy = left_entropy*len(left_x)/len(x_j) + right_entropy*len(right_x)/len(x_j)\n",
    "            info_gains.append((split_point, self.entropy - total_entropy))\n",
    "        \n",
    "        try:\n",
    "            return(max(info_gains, key = lambda x:x[1]))\n",
    "        except: return((0,0))\n",
    "        \n",
    "            \n",
    "    def do_vote(self, y_vals):\n",
    "        \n",
    "        return np.mean(y_vals)\n",
    "        \n",
    "    def fit(self,X,y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.entropy = self.get_entropy(self.y)\n",
    "        self.vote = None\n",
    "        self.split_point = None\n",
    "        self.split_col = None\n",
    "        \n",
    "        if self.X.shape[0] > self.min_obs and len(np.unique(self.y))>1 :\n",
    "            split_points, info_gains = zip(*[self.maximum_info_gain(self.X[:,x_j],self.y) for x_j in range(X.shape[1])])\n",
    "            print('prospective split points {}'.format(split_points))\n",
    "            print('prospective info_gains {}'.format(info_gains))\n",
    "            max_info_gain = max(info_gains)\n",
    "            \n",
    "            if max_info_gain == 0:\n",
    "                self.vote = self.do_vote(self.y)\n",
    "                return None\n",
    "                \n",
    "            self.split_col = info_gains.index(max_info_gain)\n",
    "            self.split_point = split_points[self.split_col]\n",
    "            self.left = DecisionTreeRegressor(min_obs = self.min_obs)\n",
    "            self.right = DecisionTreeRegressor(min_obs = self.min_obs)\n",
    "        \n",
    "            X_left, y_left = X[X[:,self.split_col] < self.split_point,:],  y[X[:,self.split_col] < self.split_point]\n",
    "            X_right, y_right = X[X[:,self.split_col] >= self.split_point,:],  y[X[:,self.split_col] >= self.split_point]\n",
    "            \n",
    "            print('splitting at column {}, value {}'.format(self.split_col, self.split_point))\n",
    "            self.left.fit(X_left, y_left)\n",
    "            self.right.fit(X_right, y_right)\n",
    "        else:\n",
    "            self.vote = self.do_vote(self.y)\n",
    "            \n",
    "    def predict_one(self, row):\n",
    "        \n",
    "        if self.X.shape[0] > self.min_obs and len(np.unique(self.y))>1:\n",
    "            if not self.split_point:\n",
    "                return self.vote\n",
    "            elif row[self.split_col] >= self.split_point:\n",
    "                return(self.right.predict_one(row))\n",
    "            else:\n",
    "                return(self.left.predict_one(row))\n",
    "        else:\n",
    "            return(self.vote)\n",
    "        \n",
    "    def predict(self, X):\n",
    "        \n",
    "        preds = []\n",
    "        for row in X:\n",
    "            preds.append(self.predict_one(row))\n",
    "        \n",
    "        return(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.arange(-25,25).reshape(50,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.array(X**3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "testRegressor = DecisionTreeRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prospective split points (-15.5,)\n",
      "prospective info_gains (1970.0033728112921,)\n",
      "splitting at column 0, value -15.5\n",
      "prospective split points (-20.5,)\n",
      "prospective info_gains (1873.2516025089813,)\n",
      "splitting at column 0, value -20.5\n",
      "prospective split points (15.5,)\n",
      "prospective info_gains (2212.054609801628,)\n",
      "splitting at column 0, value 15.5\n",
      "prospective split points (-9.5,)\n",
      "prospective info_gains (432.86399090756254,)\n",
      "splitting at column 0, value -9.5\n",
      "prospective split points (0,)\n",
      "prospective info_gains (0,)\n",
      "prospective split points (9.5,)\n",
      "prospective info_gains (567.2968672151682,)\n",
      "splitting at column 0, value 9.5\n",
      "prospective split points (-4.5,)\n",
      "prospective info_gains (97.2485635710492,)\n",
      "splitting at column 0, value -4.5\n",
      "prospective split points (4.5,)\n",
      "prospective info_gains (128.3721728454437,)\n",
      "splitting at column 0, value 4.5\n",
      "prospective split points (0,)\n",
      "prospective info_gains (0,)\n",
      "prospective split points (0,)\n",
      "prospective info_gains (0,)\n",
      "prospective split points (0,)\n",
      "prospective info_gains (0,)\n"
     ]
    }
   ],
   "source": [
    "testRegressor.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = testRegressor.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x174ddadd4a8>]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x174ddaddd68>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(X,y, alpha = 0.3)\n",
    "plt.plot(X,preds, c = 'red')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
